<!--
---
layout: home
title: shallow thoughts on deep learning  
---
-->

<!DOCTYPE html>
<html lang="en">













<head>



    <meta charset="utf-8">
    <title>Gad Mohamed</title>
    <meta name="description" content="This is Gad's Homepage">
    <meta name="author" content="Gad Mohamed">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/png" href="assets/img/me.jpg" />

    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/css/style.css">
    <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">

    <!--
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">
      -->
    <link href="https://fonts.googleapis.com/css?family=Rubik:300,500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Mansalva&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="computer_vision/assets/cv_style.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167607612-1"></script>

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-167607612-1');
    </script>


</head>

<body>
    <div id="particle-container"></div>

    <div id="container">
        <ul data-aos="fade-down" data-aos-duration="100">
            <li><a href="index.html">HOME</a></li>
            <li><a class='active' href="computer_vision_main.html ">computer vision</a></li>
            <li><a href="nlp_main.html">NLP</a></li>
            <li><a href="structured_data_main.html">structured data</a></li>
            <li><a href="ds_alg_main.html">DataStructures & Algorithms</a></li>
            <li><a href="moocs_main.html">MOOCS</a></li>
            <li><a href="publications_main.html">Publications</a></li>
        </ul>

    </div>


    <div class="blog-card">
        <div class="meta">
            <div class="photo" style="background-image: url(computer_vision/images/lane_instance_segmentation.png)"></div>

            <ul class="details tags">
                <li><a href="publications/papers/Real-Time Lane Instance Segmentation Using SegNet and Image Processing.pdf">Paper</a></li>
                <li><a href="https://github.com/gadm21/Real-time-lane-instance-segmentation">Code</a></li>
            </ul>
        </div>
        <div class="description">
            <h1>Lane instance segmentation</h1>
            <h2></h2>
            <p>
                This project was, dare I say it, an improvement on LaneNet's speed, from 0.7 FPS to 15 FPS on tesla k80, while being slightly less accurate, acheiving 91% compared to 96% by LaneNet on tuSimple dataset. This improvement was done by replacing the discriminative
                loss function branch (which uses the computationally expensive DBSCAN and mean-shift algorithms) with a simpler and faster nested sliding windows extracting each lane from a lane binary segmentation map.
            </p>
            <p style="color: burlywood;">keywords: Lane detection, instance segmentation, SegNet, sliding window, TensorFLow</p>


        </div>
    </div>



    <div class="blog-card">
        <div class="meta">
            <div class="photo" style="background-image: url(computer_vision/images/lane_detection.jpg)"></div>

            <ul class="details tags">
                <li><a href="https://github.com/gadm21/Lane-detectionn">Code</a></li>
            </ul>
        </div>
        <div class="description">
            <h1>Lane detection</h1>
            <h2>non-DL based method</h2>
            <p>
                Image processing techniques like canny edge detection, binary thresholding, perspective transformation, and histogram, are used to make a fast non-deeplearning based lane detection algorithm. The algorithm also fits the detected lanes in a 3rd order polynomial
                function to be used in following frames as a starting point to detect lanes.
            </p>
            <p style="color: burlywood;">keywords: Lane detection, perspective transformation, histogram, opencv</p>


        </div>
    </div>


    <div class="blog-card">
        <div class="meta">
            <div class="photo" style="background-image: url(computer_vision/images/image_captioning.png)"></div>

            <ul class="details tags">
                <li><a href="https://arxiv.org/abs/1411.4555">Paper</a></li>
                <li><a href="computer_vision/code/simple_clean_working_image_captioning.html">Code</a></li>
                <li><a href="https://research.googleblog.com/2014/11/a-picture-is-worth-thousand-coherent.html">Tutorial</a></li>
            </ul>
        </div>
        <div class="description">
            <h1>Image captioning</h1>
            <h2>An implementation of Google's image captioning paper</h2>
            <p> In this project, an end-to-end image captioning deep-learning-based architecture is presented based on Google's paper entitled "Show and Tell: A Neural Image Caption Generator". The architecture starts with extracting features from the input
                image using a top-less pre-trained CNN (InceptionV3 is used here). Then, LSTM units are fed the image features as an initial state as well as the caption tokens one at a time.</p>
            <p style="color: burlywood;">keywords: captioning, InceptionV3, LSTM, Keras</p>


        </div>
    </div>

    <div class="blog-card">
        <div class="meta">
            <div class="photo" style="background-image: url(https://csc.lsu.edu/~saikat/n-mnist/images/awgn_95.png)"></div>

            <ul class="details tags">
                <li><a href="computer_vision/posts/knn_report.htm">Post</a></li>
                <li><a href="computer_vision/code/noisy_mnist_code.rar">code</a></li>
            </ul>
        </div>
        <div class="description">
            <h1>Noisy MNIST classification</h1>
            <h2>using KNN to classifiy a Noisy MNIST dataset</h2>
            <p> KNN is a simple machine learning algorithm for classification tasks which requires no learning and works the best on medium-sized datasets. Here, I firstly clean the data using median filter and cropping, then I use PCA dimensionality reduction
                tool to speed up KNN by reducing feature dimension as well as increase feature quality. Finally, the model's performance is evaluated using the Leave-one-out cross-validation algorithm and confusion matrix is calculated on the testset</p>
            <p style="color: burlywood;">keywords: KNN, PCA, MNIST, median-filter, confusion matrix, Leave-one-out cross-validation</p>


        </div>
    </div>

    <div class="blog-card">
        <div class="meta">
            <div class="photo" style="background-image: url(computer_vision/images/horsevshuman.png)"></div>

            <ul class="details tags">
                <li><a href="https://github.com/gadm21/AI/blob/master/horse_human_CNN.ipynb">code</a></li>
            </ul>
        </div>
        <div class="description">
            <h1>simple CNN classifier</h1>
            <h2>classifying images of horses vs humans with CNN</h2>
            <p> In this project, I built a simple CNN classifier to classify human vs horses images (binary classfication). Image augmentation is used to increase the size of the dataset and introduce more variations and noise to the available samples. This
                project was part of the tensorflow developer professional certificates and it's meant to introduce the concept of ImageDataGenerator of keras in a simple example. </p>
            <p style="color: burlywood;">keywords: CNN, ImageDataGenerator, keras, Dropout, RMSprop, binary classification</p>


        </div>
    </div>



    <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
    <script>
        AOS.init();
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/mojs/0.265.6/mo.min.js"></script>
    <script src="https://cdn.jsdelivr.net/mojs-player/0.43.15/mojs-player.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
    <!-- <script src="assets/js/mojs.js"></script> -->
    <script src="assets/js/particle-script.js"></script>

</body>



</html>